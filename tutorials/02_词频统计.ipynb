{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPWvMoVoXgd3f+COzNNcNsL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/veager/VeNote-Natural-language-processing/blob/main/tutorials/02_%E8%AF%8D%E9%A2%91%E7%BB%9F%E8%AE%A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 词频与逆向文件频率 tf-idf"
      ],
      "metadata": {
        "id": "uAIkkTmaSBh9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 `scikit-learn` 库"
      ],
      "metadata": {
        "id": "sIn4cae9SN7u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1.1 统计词频 tf\n",
        "\n",
        "`CountVectorizer` 类"
      ],
      "metadata": {
        "id": "LqHwLAEkTthK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 语料，4 个文档\n",
        "corpus = [\n",
        "    'This is the first document.',\n",
        "    'This document is the second document.',\n",
        "    'And this is the third one.',\n",
        "    'Is this the first document?',\n",
        "]"
      ],
      "metadata": {
        "id": "ozT9bqODSdva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(analyzer='word')   # stop_words='english' 设置 stop words\n",
        "word_cnt = vectorizer.fit_transform(corpus)     # 统计 词频，返回 sparse matrix 类型\n",
        "word_cnt = word_cnt.toarray()\n",
        "\n",
        "# 输出\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(word_cnt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNFGD-HnTMqF",
        "outputId": "56946951-571b-4777-d45a-7a3d9e165e2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n",
            "[[0 1 1 1 0 0 1 0 1]\n",
            " [0 2 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 字符统计\n",
        "vectorizer1 = CountVectorizer(analyzer='char')\n",
        "word_cnt1 = vectorizer.fit_transform(corpus)\n",
        "\n",
        "# 输出\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(word_cnt1.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JT6tACQQTXmk",
        "outputId": "1195351f-d282-4416-cc5e-14f40a214c75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n",
            "[[0 1 1 1 0 0 1 0 1]\n",
            " [0 2 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# n 元模型\n",
        "vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
        "word_cnt2 = vectorizer2.fit_transform(corpus)\n",
        "\n",
        "# 输出\n",
        "print(vectorizer2.get_feature_names_out())\n",
        "print(word_cnt2.toarray())"
      ],
      "metadata": {
        "id": "UE3RK4S_EKCx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14d42f5f-51f1-4fd8-ea04-74a143884bc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['and this' 'document is' 'first document' 'is the' 'is this'\n",
            " 'second document' 'the first' 'the second' 'the third' 'third one'\n",
            " 'this document' 'this is' 'this the']\n",
            "[[0 0 1 1 0 0 1 0 0 0 0 1 0]\n",
            " [0 1 0 1 0 1 0 1 0 0 1 0 0]\n",
            " [1 0 0 1 0 0 0 0 1 1 0 1 0]\n",
            " [0 0 1 0 1 0 1 0 0 0 0 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "利用 `TfidfTransformer` 类，设置 use_idf=False，统计归一化的词频 tf"
      ],
      "metadata": {
        "id": "kd0qQVS8dLn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "# 只统计归一化的 tf, 设置 use_idf=False\n",
        "tf_norm = TfidfTransformer(use_idf=False, smooth_idf=True).fit_transform(word_cnt)\n",
        "print(tf_norm.toarray())\n",
        "\n",
        "print(word_cnt / np.linalg.norm(word_cnt, ord=2, axis=1, keepdims=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srgyFyIqdSLR",
        "outputId": "79557250-78af-4d8f-d1a1-5c9b3bdebcd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.4472136  0.4472136  0.4472136  0.         0.\n",
            "  0.4472136  0.         0.4472136 ]\n",
            " [0.         0.70710678 0.         0.35355339 0.         0.35355339\n",
            "  0.35355339 0.         0.35355339]\n",
            " [0.40824829 0.         0.         0.40824829 0.40824829 0.\n",
            "  0.40824829 0.40824829 0.40824829]\n",
            " [0.         0.4472136  0.4472136  0.4472136  0.         0.\n",
            "  0.4472136  0.         0.4472136 ]]\n",
            "[[0.         0.4472136  0.4472136  0.4472136  0.         0.\n",
            "  0.4472136  0.         0.4472136 ]\n",
            " [0.         0.70710678 0.         0.35355339 0.         0.35355339\n",
            "  0.35355339 0.         0.35355339]\n",
            " [0.40824829 0.         0.         0.40824829 0.40824829 0.\n",
            "  0.40824829 0.40824829 0.40824829]\n",
            " [0.         0.4472136  0.4472136  0.4472136  0.         0.\n",
            "  0.4472136  0.         0.4472136 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1.2 统计 idf\n",
        "\n",
        "计算 `tf-idf` 的对象 `TfidfTransformer`，经过拟合后，可以获得 `.idf_` 属性"
      ],
      "metadata": {
        "id": "cZAvFMN_T_WD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "word_cnt = [[3, 0, 1], [2, 0, 0], [3, 0, 0], [4, 0, 0], [3, 2, 0], [3, 0, 2]]\n",
        "# 6 个文档，每个文档有 3 个词\n",
        "\n",
        "transformer = TfidfTransformer(smooth_idf=True)\n",
        "transformer.fit_transform(word_cnt)\n",
        "\n",
        "print(transformer.idf_)\n",
        "print(transformer.n_features_in_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FatPMRj7EKH0",
        "outputId": "8d9df727-27d3-438f-da54-aead0bacc9d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.         2.25276297 1.84729786]\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1.3 统计 tf-idf"
      ],
      "metadata": {
        "id": "pWmAL0dQUB_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "word_cnt = [[3, 0, 1], [2, 0, 0], [3, 0, 0], [4, 0, 0], [3, 2, 0], [3, 0, 2]]\n",
        "# 6 个文档，每个文档有 3 个词\n",
        "\n",
        "transformer = TfidfTransformer(smooth_idf=True)\n",
        "# 参数: norm='l2',\n",
        "#       use_idf=True, 设所有 idf=1, 即计算归一化的词频\n",
        "#       smooth_idf=True, 是否对 idf 的计算公式平滑\n",
        "\n",
        "# 输入为 统计的词频\n",
        "tfidf = transformer.fit_transform(word_cnt)  # 返回稀疏矩阵\n",
        "print(tfidf.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGCSYaWLUKvZ",
        "outputId": "0f3c0b82-4f99-4ea3-f3b1-e424dd471c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.85151335 0.         0.52433293]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [0.55422893 0.83236428 0.        ]\n",
            " [0.63035731 0.         0.77630514]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 `NLTK` 库"
      ],
      "metadata": {
        "id": "i56zjeiaWyTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.text import TextCollection\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "corpus = [\n",
        "    'This is the first document.',\n",
        "    'This document is the second document.',\n",
        "    'And this is the third one.',\n",
        "    'Is this the first document?',\n",
        "]\n",
        "\n",
        "\n",
        "texts = TextCollection(corpus)\n",
        "\n",
        "for d, doc in enumerate(corpus):\n",
        "    # 分词\n",
        "    tokens = word_tokenize(doc)\n",
        "    # 过滤停词\n",
        "    tokens = [w for w in tokens if w not in ['.', '?']]\n",
        "\n",
        "    print('document {0}'.format(d+1))\n",
        "    # for each word\n",
        "    for w, word in enumerate(tokens):\n",
        "        tf = texts.tf(word, doc)\n",
        "        idf = texts.idf(word)\n",
        "        tf_idf = texts.tf_idf(word, doc)\n",
        "\n",
        "        print('{0:10}'.format(word), end=' ')\n",
        "        print('{0:<8.4f}'.format(tf), end=' ')\n",
        "        print('{0:<8.4f}'.format(idf), end=' ')\n",
        "        print('{0:<8.4f}'.format(tf_idf), end=' ')\n",
        "        print()\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "\n",
        "vectorizer = CountVectorizer(analyzer='word')   # stop_words='english' 设置 stop words\n",
        "word_cnt = vectorizer.fit_transform(corpus)     # 统计 词频\n",
        "\n",
        "transformer = TfidfTransformer(smooth_idf=True)\n",
        "tf_idf = transformer.fit_transform(word_cnt)\n",
        "\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(np.round(tf_idf.toarray(), 4))    # tf-idf\n",
        "print(np.round(transformer.idf_, 4))    # idf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-fsG7aUW-Xa",
        "outputId": "1ceb28ef-5df8-4f11-fd7d-78ff6483965e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "document 1\n",
            "This       0.0370   0.6931   0.0257   \n",
            "is         0.0741   0.0000   0.0000   \n",
            "the        0.0370   0.0000   0.0000   \n",
            "first      0.0370   0.6931   0.0257   \n",
            "document   0.0370   0.2877   0.0107   \n",
            "document 2\n",
            "This       0.0270   0.6931   0.0187   \n",
            "document   0.0541   0.2877   0.0156   \n",
            "is         0.0541   0.0000   0.0000   \n",
            "the        0.0270   0.0000   0.0000   \n",
            "second     0.0270   1.3863   0.0375   \n",
            "document   0.0541   0.2877   0.0156   \n",
            "document 3\n",
            "And        0.0385   1.3863   0.0533   \n",
            "this       0.0385   0.6931   0.0267   \n",
            "is         0.0769   0.0000   0.0000   \n",
            "the        0.0385   0.0000   0.0000   \n",
            "third      0.0385   1.3863   0.0533   \n",
            "one        0.0385   1.3863   0.0533   \n",
            "document 4\n",
            "Is         0.0370   1.3863   0.0513   \n",
            "this       0.0370   0.6931   0.0257   \n",
            "the        0.0370   0.0000   0.0000   \n",
            "first      0.0370   0.6931   0.0257   \n",
            "document   0.0370   0.2877   0.0107   \n",
            "['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n",
            "[[0.     0.4698 0.5803 0.3841 0.     0.     0.3841 0.     0.3841]\n",
            " [0.     0.6876 0.     0.2811 0.     0.5386 0.2811 0.     0.2811]\n",
            " [0.5118 0.     0.     0.2671 0.5118 0.     0.2671 0.5118 0.2671]\n",
            " [0.     0.4698 0.5803 0.3841 0.     0.     0.3841 0.     0.3841]]\n",
            "[1.9163 1.2231 1.5108 1.     1.9163 1.9163 1.     1.9163 1.    ]\n"
          ]
        }
      ]
    }
  ]
}